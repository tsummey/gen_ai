{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef2460e-e0cc-4b72-b65e-2488697307f3",
   "metadata": {},
   "source": [
    "***\n",
    "<span style=\"font-size:32px; color:rgba(0, 0, 255, 0.5);\">Day 2 - Embeddings & Vector Stores/Databases</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86146b8c-8a56-4f25-8762-5a855cb1a415",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\">\n",
    "  <tr>\n",
    "    <td style=\"background-color: rgba(0, 255, 0, 0.2); text-align: center; font-size: 16px;\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a345b-fc73-45fe-9ed0-b5f51266ee8f",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; color:rgba(0, 0, 0, 0.5);\">Document Q&A with RAG using Chroma</span>\n",
    "\n",
    "---\n",
    "\"Modern machine learning thrives on diverse data—images, text, audio, and more. This whitepaper explores the power of embeddings, which transform this heterogeneous data into a unified vector representation for seamless use in various applications.\n",
    "\n",
    "Why embeddings are important In essence, embeddings are numerical representations of real-world data such as text, speech, image, or videos. They are expressed as low-dimensional vectors where the geometric distances of two vectors in the vector space is a projection of the relationships between the two real-world objects that the vectors represent. In other words they help you with providing compact representations of data of different types, while simultaneously also allowing you to compare two different data objects and tell how similar or different they are on a numerical scale: for example: The word ‘computer’ has a similar meaning to the picture of a computer, as well as the word ’laptop’ but not to the word ‘car’. These low-dimensional numerical representations of real-world data significantly helps efficient large-scale data processing and storage by acting as means of lossy compression of the original data while retaining its important properties.\"\n",
    "\n",
    "<b>Authors:</b><br>\n",
    "Anant Nawalgaria and Xiaoqi Ren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef95b3b-b1aa-48c9-a509-ce405c84571a",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Resources</span>\n",
    "\n",
    "---\n",
    "**Whitepaper**<br>\n",
    "https://www.kaggle.com/whitepaper-embeddings-and-vector-stores\n",
    "\n",
    "**Embedding and Vector Stores Podcast**<br>\n",
    "https://www.youtube.com/watch?v=1CC39K76Nqs\n",
    "\n",
    "**Embedding and Vector Databases Livestream**<br>\n",
    "https://www.youtube.com/watch?v=kpRyiJUUFxY\n",
    "\n",
    "**Get your API key from**<br>\n",
    "https://aistudio.google.com/app/apikey\n",
    "\n",
    "**Kaggle**<br>\n",
    "https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27abd2-ff36-42ca-a120-cb4cb782ac46",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Retrieval Augmented Generation (RAG) - Use case example</span>\n",
    "\n",
    "---\n",
    "<b>Imagine this:</b> Employees no longer have to call, email, or hunt through HR handbooks to get answers about policies, benefits, or procedures. Instead, they can ask a chatbot and instantly get accurate, helpful responses. This would free up an HR team’s time and allow them to focus on bigger priorities.\n",
    "\n",
    "Here’s how it works:\n",
    "\n",
    "1. Understanding Your Documents: All your HR materials—handbooks, policies, guides—are analyzed and broken down into smaller, easy-to-digest sections (like bite-sized chunks).<br><br>\n",
    "2. Making the Chatbot Smart: These chunks are converted into a special, searchable format that helps the AI understand the meaning of each section, not just the words. Think of it like creating a quick-reference map for all your documents.<br><br>\n",
    "3. Fast, Accurate Answers: When an employee asks the chatbot a question, the system compares the question to the document map and finds the best, most relevant answer in seconds.<br><br>\n",
    "4. Keeping Things Updated: Since HR documents change frequently, the system stays up-to-date by:<br><br>\n",
    "   <ul>\n",
    "       <li>\n",
    "           <b>Scheduling Regular Updates:</b> Reprocessing all documents periodically.\n",
    "       </li><br>\n",
    "       <li>\n",
    "           <b>Real-Time Monitoring:</b> Automatically updating the system when changes are detected.\n",
    "       </li><br>\n",
    "       <li>\n",
    "           <b>Tagging Versions:</b> Keeping both current and historical versions of information if needed.\n",
    "       </li><br>\n",
    "   </ul>\n",
    "This approach ensures employees always get accurate answers, even as policies or procedures evolve. It’s like having an HR assistant on call 24/7—efficient, accurate, and stress-free for everyone involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5f6e2-284d-4a6a-82eb-2458d61e1182",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px; color:rgba(0, 0, 0, 0.5);\">How are vectors compared?</span>\n",
    "\n",
    "- Vectors are arrays of numbers, like [0.1, 0.3, 0.5], where each value represents a specific feature or aspect of the data.\n",
    "- The goal is to measure the \"distance\" or \"angle\" between two vectors to assess how related they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a03ec-731e-4768-989d-e14541256a91",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px; color:rgba(0, 0, 0, 0.5);\">Simple RAG Diagram - HR Example</span>\n",
    "![Alt Text](./images/hr_rag_dia.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2b396c-a7ad-4dfc-a12c-ee2222260ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2322de7d-791b-4bc1-ac4c-8edd69655512",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Libraries</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876a7d3c-f968-461c-bbc7-92586e8e12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, chromadb\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.api_core import retry\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd9899-65b3-4a3d-91dd-8d34a834b05f",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Initialize the API</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235aa623-e87f-4860-b328-1d442affaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GAI_API_KEY\")\n",
    "\n",
    "# Set up the API key for the genai library\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef327d-edd1-4a68-a9c4-da0e04e8e58b",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Explore available models</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614e89d6-02c4-482f-b32a-a514cca18ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if \"embedContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e02b3d0-0efb-40c8-9b60-2db48928fdf9",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Data</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3851be-1462-4a51-9462-b8e1752b33a6",
   "metadata": {},
   "source": [
    "Here is a small set of documents you will use to create an embedding database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbda942a-3d31-4927-9bf7-3b21a085e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT1 = \"Operating the Climate Control System  Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"\n",
    "DOCUMENT2 = 'Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.'\n",
    "DOCUMENT3 = \"Shifting Gears Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"\n",
    "\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6397f-aab1-4604-be71-78129e80bbcd",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Creating the embedding database with ChromaDB</span>\n",
    "\n",
    "---\n",
    "Create a custom function to generate embeddings with the Gemini API. In this task, you are implementing a retrieval system, so the task_type for generating the document embeddings is retrieval_document. Later, you will use retrieval_query for the query embeddings. Check out the API reference for the full list of supported tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e002210-628e-41db-adcd-02b517bb399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    document_mode = True\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
    "\n",
    "        response = genai.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            content=input,\n",
    "            task_type=embedding_task,\n",
    "            request_options=retry_policy,\n",
    "        )\n",
    "        return response[\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d3e4c6-4a8b-4c31-8109-d3a1f0de67b5",
   "metadata": {},
   "source": [
    "Now create a Chroma database client that uses the GeminiEmbeddingFunction and populate the database with the documents you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216165c4-3f6a-42ea-9085-e1c907fdf713",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"googlecardb\"\n",
    "embed_fn = GeminiEmbeddingFunction()\n",
    "embed_fn.document_mode = True\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be9728-d326-4f04-87e0-7c45d279207c",
   "metadata": {},
   "source": [
    "Confirm that the data was inserted by looking at the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33530860-ea3c-491b-94bb-61ada59831e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.count()\n",
    "# You can peek at the data too.\n",
    "# db.peek(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80329d6e-64e2-4481-9a58-e907df6d7e00",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Retrieval: Find relevant documents</span>\n",
    "\n",
    "---\n",
    "Retrieval: Find relevant documents\n",
    "To search the Chroma database, call the query method. Note that you also switch to the retrieval_query mode of embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d08d5a0-5b48-4c41-81f1-defc1bb0fd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch to query mode when generating embeddings.\n",
    "embed_fn.document_mode = False\n",
    "\n",
    "# Search the Chroma DB using the specified query.\n",
    "query = \"How do you use the touchscreen to play music?\"\n",
    "\n",
    "result = db.query(query_texts=[query], n_results=1)\n",
    "[[passage]] = result[\"documents\"]\n",
    "\n",
    "Markdown(passage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc0c7e-7f11-4df5-9bf5-292d07beee52",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Augmented generation: Answer the question</span>\n",
    "\n",
    "---\n",
    "Now that you have found a relevant passage from the set of documents (the retrieval step), you can now assemble a generation prompt to have the Gemini API generate a final answer. Note that in this example only a single passage was retrieved. In practice, especially when the size of your underlying data is large, you will want to retrieve more than one result and let the Gemini model determine what passages are relevant in answering the question. For this reason it's OK if some retrieved passages are not directly related to the question - this generation step should ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e0e040-6030-42e2-8a51-8273c775ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
      "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
      "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
      "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
      "\n",
      "QUESTION: How do you use the touchscreen to play music?\n",
      "PASSAGE: Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "\n",
    "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "PASSAGE: {passage_oneline}\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afe95f8-63c8-43cd-b5fb-bd0f07d5f50d",
   "metadata": {},
   "source": [
    "Now use the generate_content method to to generate an answer to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0527a1-91a2-46bc-87bb-c42a2c81aeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To play music on your Googlecar's touchscreen, simply touch the \"Music\" icon; it's that easy!  The touchscreen is the large display that shows all the car's features, including navigation and climate control, so you just tap the icon to start playing your music.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2b95c-8b71-49b9-8cdd-30cf65cadacd",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Next Steps</span>\n",
    "\n",
    "---\n",
    "To learn more about using embeddings in the Gemini API, check out the Intro to embeddings or to learn more fundamentals, study the embeddings chapter of the Machine Learning Crash Course.\n",
    "\n",
    "For a hosted RAG system, check out the Semantic Retrieval service in the Gemini API. You can implement question-answering on your own documents in a single request, or host a database for even faster responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a59b8-1eeb-44ee-a5e5-079498a509ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
