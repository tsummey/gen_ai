{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e014fbf-93dc-4e3d-8980-66e14ccf9827",
   "metadata": {},
   "source": [
    "***\n",
    "<span style=\"font-size:32px; color:rgba(0, 0, 255, 0.5);\">Day 2 - Embeddings & Vector Stores/Databases</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0988e633-da4c-4d60-8db5-15e5bf202062",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\">\n",
    "  <tr>\n",
    "    <td style=\"background-color: rgba(0, 255, 0, 0.2); text-align: center; font-size: 16px;\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3c4c23-aa4e-4338-ad60-8db550dd51dd",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; color:rgba(0, 0, 0, 0.5);\">Classifying embeddings with Keras and the Gemini API</span>\n",
    "\n",
    "---\n",
    "\"Modern machine learning thrives on diverse data—images, text, audio, and more. This whitepaper explores the power of embeddings, which transform this heterogeneous data into a unified vector representation for seamless use in various applications.\n",
    "\n",
    "Why embeddings are important In essence, embeddings are numerical representations of real-world data such as text, speech, image, or videos. They are expressed as low-dimensional vectors where the geometric distances of two vectors in the vector space is a projection of the relationships between the two real-world objects that the vectors represent. In other words they help you with providing compact representations of data of different types, while simultaneously also allowing you to compare two different data objects and tell how similar or different they are on a numerical scale: for example: The word ‘computer’ has a similar meaning to the picture of a computer, as well as the word ’laptop’ but not to the word ‘car’. These low-dimensional numerical representations of real-world data significantly helps efficient large-scale data processing and storage by acting as means of lossy compression of the original data while retaining its important properties.\"\n",
    "\n",
    "<b>Authors:</b><br>\n",
    "Anant Nawalgaria and Xiaoqi Ren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e420cbf5-0932-43c2-94d9-4731ce1b56a9",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Resources</span>\n",
    "\n",
    "---\n",
    "**Whitepaper**<br>\n",
    "https://www.kaggle.com/whitepaper-embeddings-and-vector-stores\n",
    "\n",
    "**Embedding and Vector Stores Podcast**<br>\n",
    "https://www.youtube.com/watch?v=1CC39K76Nqs\n",
    "\n",
    "**Embedding and Vector Databases Livestream**<br>\n",
    "https://www.youtube.com/watch?v=kpRyiJUUFxY\n",
    "\n",
    "**Get your API key from**<br>\n",
    "https://aistudio.google.com/app/apikey\n",
    "\n",
    "**Kaggle**<br>\n",
    "https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f87138-864e-4ab7-8250-88287412508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8634dcf-a9ec-4dd0-bd59-77dc275f998d",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Libraries</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b3aaeed-76c7-4fa8-ab6f-c3d709cb1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, email, re, keras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.api_core import retry\n",
    "\n",
    "from tqdm.rich import tqdm\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "import warnings\n",
    "from tqdm import TqdmExperimentalWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e4019-4b48-40a3-a2a2-099889f1d7fc",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Initialize the API</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75fe083-4394-48dc-98c2-4de77d98ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GAI_API_KEY\")\n",
    "\n",
    "# Set up the API key for the genai library\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb2ed7-4677-427c-999d-409e828542b1",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Dataset</span>\n",
    "\n",
    "---\n",
    "The 20 Newsgroups Text Dataset contains 18,000 newsgroups posts on 20 topics divided into training and test sets. The split between the training and test datasets are based on messages posted before and after a specific date. For this tutorial, you will use sampled subsets of the training and test sets, and perform some processing using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70382364-c1d2-4435-b8f1-f7c34f801b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7467976-a444-4e52-831c-e65800244152",
   "metadata": {},
   "source": [
    "Here is an example of what a record from the training set looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d65549-2647-49d8-8e58-e5e37d02e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98ffa2-35f5-4065-868a-4b3a8b786517",
   "metadata": {},
   "source": [
    "Start by preprocessing the data for this tutorial in a Pandas dataframe. To remove any sensitive information like names and email addresses, you will take only the subject and body of each message. This is an optional step that transforms the input data into more generic text, rather than email posts, so that it will work in other contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad87691f-5ed5-413c-8e04-deeb8a29cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_newsgroup_row(data):\n",
    "    # Extract only the subject and body\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    # Strip any remaining email addresses\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    # Truncate each entry to 5,000 characters\n",
    "    text = text[:5000]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Put data points into dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n",
    "    )\n",
    "    # Clean up the text\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    # Match label to target name index\n",
    "    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abdd2968-42ad-4644-a69d-ef661ae3a12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
       "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
       "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
       "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
       "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ce61b-0e7d-4bea-9b25-58daf0bd7e0e",
   "metadata": {},
   "source": [
    "Next, you will sample some of the data by taking 100 data points in the training dataset, and dropping a few of the categories to run through this tutorial. Choose the science categories to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52a1bfc-c2da-4f63-8da5-fe7f40f0d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Sample rows, selecting num_samples of each Label.\n",
    "    df = (\n",
    "        df.groupby(\"Label\")[df.columns]\n",
    "        .apply(lambda x: x.sample(num_samples))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "\n",
    "    # We have fewer categories now, so re-calibrate the label encoding.\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09660619-b13e-4649-9f61-9ba069c6745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = \"sci\"  # Class name should contain 'sci' to keep science categories\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "638c2326-5f30-44a7-bdbc-4cf6f2dfc103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          100\n",
       "sci.electronics    100\n",
       "sci.med            100\n",
       "sci.space          100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.value_counts(\"Class Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88899c57-044c-4e22-af3f-7dc1e6764fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          25\n",
       "sci.electronics    25\n",
       "sci.med            25\n",
       "sci.space          25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.value_counts(\"Class Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62cfe66-6e6d-4618-b9df-f29697d848a0",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Create the embeddings</span>\n",
    "\n",
    "---\n",
    "In this section, you will generate embeddings for each piece of text using the Gemini API embeddings endpoint. To learn more about embeddings, visit the embeddings guide.\n",
    "\n",
    "NOTE: Embeddings are computed one at a time, so large sample sizes can take a long time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71909e-f025-4e97-8b24-6647d7b36a70",
   "metadata": {},
   "source": [
    "<span style=\"font-size:16px; color:rgba(0, 0, 0, 0.5);\">Task Types</span>\n",
    "\n",
    "<p>The `text-embedding-004` model supports a task type parameter that generates embeddings tailored for the specific task.</p>\n",
    "\n",
    "<div style=\"text-align: left; display: inline-block;\">\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"text-align: left;\">Task Type</th>\n",
    "      <th style=\"text-align: left;\">Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>RETRIEVAL_QUERY</td>\n",
    "      <td>Specifies the given text is a query in a search/retrieval setting.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>RETRIEVAL_DOCUMENT</td>\n",
    "      <td>Specifies the given text is a document in a search/retrieval setting.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>SEMANTIC_SIMILARITY</td>\n",
    "      <td>Specifies the given text will be used for Semantic Textual Similarity (STS).</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>CLASSIFICATION</td>\n",
    "      <td>Specifies that the embeddings will be used for classification.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>CLUSTERING</td>\n",
    "      <td>Specifies that the embeddings will be used for clustering.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>FACT_VERIFICATION</td>\n",
    "      <td>Specifies that the given text will be used for fact verification.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "<p>For this example, you will be performing classification.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a462d905-9962-4cc2-bd1f-9fb0b736ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "@retry.Retry(timeout=300.0)\n",
    "def embed_fn(text: str) -> list[float]:\n",
    "    # You will be performing classification, so set task_type accordingly.\n",
    "    response = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\", content=text, task_type=\"classification\"\n",
    "    )\n",
    "\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "\n",
    "def create_embeddings(df):\n",
    "    df[\"Embeddings\"] = df[\"Text\"].progress_apply(embed_fn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be688f5b-0a7d-4e41-83a1-d037fa920d38",
   "metadata": {},
   "source": [
    "This code is optimised for clarity, and is not particularly fast. It is left as an exercise for the reader to implement batch or parallel/asynchronous embedding generation. Running this step will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1074986d-303a-4513-a0eb-975e97d2b181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2190afed034e649ebf5ee90b3fe62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca6b24558d14452aeee9593334a48f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = create_embeddings(df_train)\n",
    "df_test = create_embeddings(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e567a7e-d94f-4969-b640-e2e91fc01a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Encoded Label</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Re: Once tapped, your code is no good any more...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.010045305, 0.014250235, -0.03582837, 0.035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Re: Would \"clipper\" make a good cover for othe...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.009308786, 0.029653585, -0.04822619, 0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>Re: text of White House announcement and Q&amp;As ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.032723654, 0.033324193, -0.036674835, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>Re: Once tapped, your code is no good any more...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010096876, 0.0068887677, -0.024978861, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>Re: Hard drive security for FBI targets\\n\\n (R...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.010112229, 0.022346703, -0.046342988, 0.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label Class Name  \\\n",
       "1100  Re: Once tapped, your code is no good any more...     11  sci.crypt   \n",
       "1101  Re: Would \"clipper\" make a good cover for othe...     11  sci.crypt   \n",
       "1102  Re: text of White House announcement and Q&As ...     11  sci.crypt   \n",
       "1103  Re: Once tapped, your code is no good any more...     11  sci.crypt   \n",
       "1104  Re: Hard drive security for FBI targets\\n\\n (R...     11  sci.crypt   \n",
       "\n",
       "      Encoded Label                                         Embeddings  \n",
       "1100              0  [-0.010045305, 0.014250235, -0.03582837, 0.035...  \n",
       "1101              0  [-0.009308786, 0.029653585, -0.04822619, 0.029...  \n",
       "1102              0  [-0.032723654, 0.033324193, -0.036674835, -0.0...  \n",
       "1103              0  [0.010096876, 0.0068887677, -0.024978861, 0.04...  \n",
       "1104              0  [-0.010112229, 0.022346703, -0.046342988, 0.02...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8fb343-65dd-4615-85d8-faee04649bd9",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Build a classification model</span>\n",
    "\n",
    "---\n",
    "Here you will define a simple model that accepts the raw embedding data as input, has one hidden layer, and an output layer specifying the class probabilities. The prediction will correspond to the probability of a piece of text being a particular class of news.\n",
    "\n",
    "When you run the model, Keras will take care of details like shuffling the data points, calculating metrics and other ML boilerplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fac5115-5beb-49b3-a4a8-fe205f7a417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input([input_size], name=\"embedding_inputs\"),\n",
    "            layers.Dense(input_size, activation=\"relu\", name=\"hidden\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output_probs\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e86592f-0e7f-4cec-8838-f2a281588a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_probs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,076</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │       \u001b[38;5;34m590,592\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_probs (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m3,076\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">593,668</span> (2.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m593,668\u001b[0m (2.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Derive the embedding size from observing the data. The embedding size can also be specified\n",
    "# with the `output_dimensionality` parameter to `embed_content` if you need to reduce it.\n",
    "embedding_size = len(df_train[\"Embeddings\"].iloc[0])\n",
    "\n",
    "classifier = build_classification_model(\n",
    "    embedding_size, len(df_train[\"Class Name\"].unique())\n",
    ")\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6fb46-81a8-4b6a-939c-93598ddfa2e4",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Train the model</span>\n",
    "\n",
    "---\n",
    "Finally, you can train your model. This code uses early stopping to exit the training loop once the loss value stabilises, so the number of epoch loops executed may differ from the specified value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81ed67f8-cd5d-406f-b04e-05094769124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.2586 - loss: 1.3697 - val_accuracy: 0.5200 - val_loss: 1.2926\n",
      "Epoch 2/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8197 - loss: 1.2031 - val_accuracy: 0.7900 - val_loss: 1.1586\n",
      "Epoch 3/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 1.0298 - val_accuracy: 0.8000 - val_loss: 1.0211\n",
      "Epoch 4/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8255 - loss: 0.8392 - val_accuracy: 0.8000 - val_loss: 0.8901\n",
      "Epoch 5/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9443 - loss: 0.6517 - val_accuracy: 0.8500 - val_loss: 0.7464\n",
      "Epoch 6/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.4644 - val_accuracy: 0.8600 - val_loss: 0.6446\n",
      "Epoch 7/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9576 - loss: 0.3825 - val_accuracy: 0.8700 - val_loss: 0.5640\n",
      "Epoch 8/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.2809 - val_accuracy: 0.8900 - val_loss: 0.4947\n",
      "Epoch 9/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.2294 - val_accuracy: 0.8800 - val_loss: 0.4744\n",
      "Epoch 10/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.1952 - val_accuracy: 0.8800 - val_loss: 0.4370\n",
      "Epoch 11/20\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.1603 - val_accuracy: 0.8400 - val_loss: 0.4300\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Split the x and y components of the train and validation subsets.\n",
    "y_train = df_train[\"Encoded Label\"]\n",
    "x_train = np.stack(df_train[\"Embeddings\"])\n",
    "y_val = df_test[\"Encoded Label\"]\n",
    "x_val = np.stack(df_test[\"Embeddings\"])\n",
    "\n",
    "# Specify that it's OK to stop early if accuracy stabilises.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n",
    "\n",
    "# Train the model for the desired number of epochs.\n",
    "history = classifier.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e00f6dc-dec1-4b4e-86d9-052b8fe07242",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Evaluate model performance</span>\n",
    "\n",
    "---\n",
    "Use Keras Model.evaluate to calculate the loss and accuracy on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5552b3f-6fb5-41b8-a9a0-573656dd14f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.4105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8399999737739563, 'loss': 0.4300147294998169}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x=x_val, y=y_val, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63646ed2-748d-482e-9d39-b8dfac1637ad",
   "metadata": {},
   "source": [
    "To learn more about training models with Keras, including how to visualise the model training metrics, read <u>[Training & evaluation with built-in methods](https://www.tensorflow.org/guide/keras/training_with_built_in_methods)</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e11e8-ce01-4119-8cf6-2d83b0abe3e8",
   "metadata": {},
   "source": [
    "<span style=\"font-size:18px; color:rgba(0, 0, 0, 0.5);\">Try a custom prediction</span>\n",
    "\n",
    "---\n",
    "Now that you have a trained model with good evaluation metrics, you can try to make a prediction with new, hand-written data. Use the provided example or try your own data to see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "003f4620-ef17-46d4-b4fe-aa911154c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example avoids any space-specific terminology to see if the model avoids\n",
    "# biases towards specific jargon.\n",
    "new_text = \"\"\"\n",
    "First-timer looking to get out of here.\n",
    "\n",
    "Hi, I'm writing about my interest in travelling to the outer limits!\n",
    "\n",
    "What kind of craft can I buy? What is easiest to access from this 3rd rock?\n",
    "\n",
    "Let me know how to do that please.\n",
    "\"\"\"\n",
    "embedded = embed_fn(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d69115ae-2ff5-4b83-9b49-7157151a1990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "sci.crypt: 0.62%\n",
      "sci.electronics: 1.50%\n",
      "sci.med: 0.21%\n",
      "sci.space: 97.68%\n"
     ]
    }
   ],
   "source": [
    "# Remember that the model takes embeddings as input, and the input must be batched,\n",
    "# so here they are passed as a list to provide a batch of 1.\n",
    "inp = np.array([embedded])\n",
    "[result] = classifier.predict(inp)\n",
    "\n",
    "for idx, category in enumerate(df_test[\"Class Name\"].cat.categories):\n",
    "    print(f\"{category}: {result[idx] * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667297c-27fb-436e-ad12-7533ae26a28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
